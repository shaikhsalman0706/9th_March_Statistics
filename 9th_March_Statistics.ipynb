{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15193c7",
   "metadata": {},
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287d3c8",
   "metadata": {},
   "source": [
    "#### Probability Mass Function (PMF) and Probability Density Function (PDF) are both used to describe the probability distribution of a random variable. The difference between them lies in the type of random variable they apply to.\n",
    "\n",
    "#### The Probability Mass Function (PMF) is used for discrete random variables, which can only take on a finite or countably infinite set of values. The PMF gives the probability that the random variable takes on each possible value. Mathematically, the PMF is defined as:\n",
    "\n",
    "###### P(X=x) = probability that X takes on the value x\n",
    "\n",
    "###### For example, consider rolling a fair six-sided die. The random variable X represents the outcome of the roll, which can take on values 1, 2, 3, 4, 5, or 6. The PMF for X is:\n",
    "\n",
    "#### P(X=1) = 1/6\n",
    "#### P(X=2) = 1/6\n",
    "#### P(X=3) = 1/6\n",
    "#### P(X=4) = 1/6\n",
    "#### P(X=5) = 1/6\n",
    "#### P(X=6) = 1/6\n",
    "\n",
    "#### The sum of all the probabilities must equal 1, since one of these outcomes must occur when we roll the die.\n",
    "\n",
    "###### On the other hand, the Probability Density Function (PDF) is used for continuous random variables, which can take on any value in a continuous range. The PDF gives the relative likelihood of the random variable taking on each possible value. Mathematically, the PDF is defined as:\n",
    "##### f(x) = probability density at x\n",
    "\n",
    "###### The probability of the random variable taking on a particular value is given by the area under the PDF curve between two values. For example, consider the normal distribution with mean μ = 0 and standard deviation σ = 1. The PDF for this distribution is:\n",
    "\n",
    "##### f(x) = (1/√(2π)) * e^(-(x^2)/2)\n",
    "\n",
    "###### The probability of the random variable X taking on a value between a and b is given by the area under the curve of the PDF between a and b:\n",
    "\n",
    "#### P(a ≤ X ≤ b) = ∫a^b f(x)dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9a91c",
   "metadata": {},
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b21d63",
   "metadata": {},
   "source": [
    "#### The Cumulative Density Function (CDF) is a mathematical function that describes the probability that a random variable takes on a value less than or equal to a given value. It is defined for both discrete and continuous random variables and is used to characterize the distribution of the random variable.\n",
    "\n",
    "###### For a discrete random variable X, the CDF is defined as:\n",
    "\n",
    "##### F(x) = P(X ≤ x)\n",
    "\n",
    "###### This function gives the cumulative probability of the random variable taking on a value less than or equal to x. For example, consider the same fair six-sided die from the previous question. The CDF for X is:\n",
    "\n",
    "#### F(x) = P(X ≤ x)\n",
    "####\n",
    "#### F(1) = 1/6\n",
    "#### F(2) = 2/6\n",
    "#### F(3) = 3/6\n",
    "#### F(4) = 4/6\n",
    "#### F(5) = 5/6\n",
    "#### F(6) = 6/6 = 1\n",
    "\n",
    "#### The CDF is a step function that increases by 1/n at each possible value of X.\n",
    "\n",
    "###### For a continuous random variable X, the CDF is defined as:\n",
    "\n",
    "#### F(x) = P(X ≤ x) = ∫-∞^x f(t)dt\n",
    "\n",
    "#### where f(t) is the probability density function of X. This function gives the cumulative probability of the random variable taking on a value less than or equal to x.\n",
    "\n",
    "###### For example, consider the normal distribution with mean μ = 0 and standard deviation σ = 1. The CDF for this distribution is:\n",
    "\n",
    "##### F(x) = P(X ≤ x) = ∫-∞^x f(t)dt\n",
    "\n",
    "##### F(x) = (1/√(2π)) ∫-∞^x e^(-(t^2)/2)dt\n",
    "\n",
    "#### The CDF for the normal distribution is not easily computable, but it can be approximated using numerical methods or looked up in tables.\n",
    "\n",
    "###### The CDF is used to calculate probabilities of events that involve the random variable. For example, the probability of the random variable taking on a value between a and b for a continuous random variable X is given by:\n",
    "\n",
    "#### P(a ≤ X ≤ b) = F(b) - F(a)\n",
    "\n",
    "###### The CDF is also useful for generating random samples from a distribution using inverse transform sampling or other methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4758dd1",
   "metadata": {},
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37d82f",
   "metadata": {},
   "source": [
    "#### The normal distribution, also known as the Gaussian distribution, is a probability distribution that is commonly used to model real-world phenomena where the data is continuous and symmetrically distributed around the mean. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "###### 1. Heights of individuals: The heights of people in a large population are often normally distributed, with a mean height and a standard deviation that determines the spread of the distribution.\n",
    "\n",
    "###### 2. Test scores: In large groups of students taking a standardized test, the distribution of scores is often approximately normal, with a mean score and a standard deviation that determine the spread of the distribution.\n",
    "\n",
    "###### 3. Measurement errors: In many scientific experiments, measurement errors can be assumed to be normally distributed, with a mean of zero and a standard deviation that represents the magnitude of the error.\n",
    "\n",
    "###### 4. Stock prices: The daily changes in stock prices of large companies can often be modeled as a normal distribution, with a mean return and a standard deviation that represents the volatility of the stock.\n",
    "\n",
    "#### The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, while the standard deviation represents the spread of the distribution.\n",
    "\n",
    "#### The mean determines the location of the peak of the distribution. If the mean is larger, the peak will be shifted to the right, while if the mean is smaller, the peak will be shifted to the left. The standard deviation determines the width of the distribution. A smaller standard deviation means that the distribution is more tightly clustered around the mean, while a larger standard deviation means that the distribution is more spread out.\n",
    "\n",
    "#### The normal distribution is often used as a model because of the central limit theorem, which states that the distribution of the sum or average of a large number of independent and identically distributed random variables will approach a normal distribution, regardless of the underlying distribution of the variables. This makes the normal distribution a useful tool for statistical inference and hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8a62b",
   "metadata": {},
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f00bf",
   "metadata": {},
   "source": [
    "#### The normal distribution is one of the most important probability distributions in statistics, with many applications in real-life scenarios. Here are some reasons why the normal distribution is important:\n",
    "\n",
    "###### 1. The normal distribution is easy to work with mathematically, which makes it a useful tool for modeling real-world phenomena and for making statistical inferences.\n",
    "\n",
    "###### 2. Many natural processes and phenomena can be modeled using the normal distribution, due to the central limit theorem. This makes the normal distribution a versatile and widely used tool in many areas of science and engineering.\n",
    "\n",
    "###### 3. Many statistical techniques, such as hypothesis testing and confidence intervals, are based on the normal distribution or on assumptions of normality. This makes the normal distribution a fundamental concept in statistical inference.\n",
    "\n",
    "#### Here are some examples of real-life situations where the normal distribution can be observed:\n",
    "\n",
    "###### 1. Heights of individuals: The heights of people in a large population are often normally distributed, with a mean height and a standard deviation that determine the spread of the distribution.\n",
    "\n",
    "###### 2. IQ scores: IQ scores are often assumed to be normally distributed, with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "###### 3. Body temperatures: Body temperatures in healthy adults are normally distributed, with a mean of 98.6°F and a standard deviation of about 0.7°F.\n",
    "\n",
    "###### 4.Test scores: In large groups of students taking a standardized test, the distribution of scores is often approximately normal, with a mean score and a standard deviation that determine the spread of the distribution.\n",
    "\n",
    "###### 5. Stock prices: The daily changes in stock prices of large companies can often be modeled as a normal distribution, with a mean return and a standard deviation that represents the volatility of the stock.\n",
    "\n",
    "###### 6. Measurement errors: In many scientific experiments, measurement errors can be assumed to be normally distributed, with a mean of zero and a standard deviation that represents the magnitude of the error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc637b47",
   "metadata": {},
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce69d7",
   "metadata": {},
   "source": [
    "#### The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success and failure. It is named after Swiss mathematician Jacob Bernoulli, who used it to model coin tosses.\n",
    "\n",
    "#### In the Bernoulli distribution, a single trial has a probability of success (denoted by p) and a probability of failure (denoted by 1-p). The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "###### P(X=k) = p^k(1-p)^(1-k) for k=0,1\n",
    "\n",
    "where X is a random variable that takes the value 1 for a success and 0 for a failure.\n",
    "\n",
    "Here is an example of the Bernoulli distribution: Suppose you flip a fair coin once. The Bernoulli distribution can be used to model the probability of getting heads (success) or tails (failure). In this case, p=0.5 and 1-p=0.5.\n",
    "\n",
    "The Binomial distribution is an extension of the Bernoulli distribution that models the number of successes in a fixed number of independent Bernoulli trials. It is named after French mathematician Jacques Binomial.\n",
    "\n",
    "In the Binomial distribution, there are n independent trials, each with a probability of success p. The probability mass function (PMF) of the Binomial distribution is:\n",
    "\n",
    "###### P(X=k) = (n choose k) * p^k * (1-p)^(n-k) for k=0,1,2,...,n\n",
    "\n",
    "where X is a random variable that represents the number of successes in the n trials.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution models a single trial with two possible outcomes, while the Binomial distribution models the number of successes in a fixed number of independent trials. The Bernoulli distribution can be seen as a special case of the Binomial distribution, where n=1.\n",
    "\n",
    "Here is an example of the Binomial distribution: Suppose you flip a fair coin 10 times. The Binomial distribution can be used to model the number of heads (successes) that you get out of the 10 flips, with p=0.5 and n=10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3682f545",
   "metadata": {},
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53b12f",
   "metadata": {},
   "source": [
    "#### To solve this problem, we need to use the properties of the normal distribution and the standard normal distribution. We can standardize the observation of interest by subtracting the mean and dividing by the standard deviation, which will give us a standard normal distribution with mean 0 and standard deviation 1. We can then use a table or calculator to find the probability that a standard normal variable is greater than a certain value.\n",
    "\n",
    "#### Here's the solution:\n",
    "\n",
    "#### First, we standardize the observation of interest:\n",
    "\n",
    "#### Z = (60 - 50) / 10 = 1\n",
    "\n",
    "#### where Z is the standard normal variable.\n",
    "\n",
    "#### Next, we find the probability that Z is greater than 1 using a standard normal distribution table or calculator. From a standard normal distribution table, we find that the probability of Z being greater than 1 is approximately 0.1587.\n",
    "\n",
    "#### Therefore, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3a9e7",
   "metadata": {},
   "source": [
    "### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e43167",
   "metadata": {},
   "source": [
    "#### Uniform distribution is a continuous probability distribution where all values within a specific range are equally likely to occur. It is often used to model situations where there is no preference or bias towards any particular value within a given interval.\n",
    "\n",
    "#### The probability density function (PDF) of a uniform distribution is:\n",
    "\n",
    "###### f(x) = 1 / (b - a) for a <= x <= b\n",
    "\n",
    "###### where a and b are the minimum and maximum values of the distribution.\n",
    "\n",
    "#### Here is an example of a uniform distribution: Suppose we roll a fair six-sided die. The values 1, 2, 3, 4, 5, and 6 are equally likely to occur, and there is no preference or bias towards any particular value. We can model this situation using a uniform distribution with a=1 and b=6, where a is the minimum possible value (1) and b is the maximum possible value (6).\n",
    "\n",
    "#### The PDF of this uniform distribution is:\n",
    "\n",
    "###### f(x) = 1 / (6 - 1) = 1/5 for 1 <= x <= 6\n",
    "\n",
    "#### This means that the probability of getting any particular value on the die is 1/6, which is the same for all possible values. The cumulative density function (CDF) of the uniform distribution is:\n",
    "\n",
    "###### F(x) = (x - a) / (b - a) for a <= x <= b\n",
    "\n",
    "###### = 0 for x < a\n",
    "\n",
    "###### = 1 for x >= b\n",
    "\n",
    "#### The CDF gives us the probability that a randomly selected value from the distribution is less than or equal to a particular value x. In the case of the die roll example, the CDF would give us the probability of rolling a number less than or equal to a given value on the die."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd1410",
   "metadata": {},
   "source": [
    " ### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136f774",
   "metadata": {},
   "source": [
    "#### The z-score, also known as the standard score, is a measure of how many standard deviations a data point is away from the mean of a distribution. It is calculated by subtracting the mean of the distribution from the data point and then dividing by the standard deviation of the distribution:\n",
    "\n",
    "###### z = (x - μ) / σ\n",
    "\n",
    "#### where x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "#### The z-score is important because it allows us to compare values from different normal distributions on a common scale. By standardizing the data using the z-score, we can find the probability of getting a value less than or greater than a particular value, or the probability of getting a value within a certain range. This can be done using a standard normal distribution table or calculator, which gives us the probability for a standard normal distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "#### In addition, the z-score can be used to identify outliers in a dataset. Data points with a z-score greater than 3 or less than -3 are typically considered outliers, as they are more than three standard deviations away from the mean of the distribution.\n",
    "\n",
    "#### Overall, the z-score is a powerful tool for analyzing and interpreting data, and it is widely used in statistics and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352cce9",
   "metadata": {},
   "source": [
    "### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a46b8",
   "metadata": {},
   "source": [
    "#### The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics. It states that, under certain conditions, the sum or average of a large number of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the underlying distribution of the individual variables.\n",
    "\n",
    "#### The conditions required for the CLT to hold are:\n",
    "\n",
    "###### 1. The sample size must be large enough (usually n >= 30) for the distribution of the sample mean to be approximately normal.\n",
    "\n",
    "###### 2. The observations must be independent and identically distributed.\n",
    "\n",
    "#### The significance of the CLT is that it allows us to use normal distribution theory to approximate the distribution of sample means, even if the underlying distribution of the individual variables is not known or is not normally distributed. This is particularly useful in practice, where we often have a sample of data but do not know the distribution of the population.\n",
    "\n",
    "#### The CLT has important applications in fields such as quality control, finance, and medical research. For example, it can be used to estimate the mean and standard deviation of a population based on a sample, or to test hypotheses about the mean of a population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f620cb",
   "metadata": {},
   "source": [
    "### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533b77c",
   "metadata": {},
   "source": [
    "#### The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics, and it states that under certain conditions, the sum or average of a large number of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the underlying distribution of the individual variables. The assumptions required for the CLT to hold are:\n",
    "\n",
    "###### 1. Independence: The observations in the sample must be independent of each other. That is, the value of one observation should not be influenced by the values of other observations in the sample.\n",
    "\n",
    "###### 2. Identically distributed: The individual variables in the sample must be identically distributed. This means that each variable has the same probability distribution and the same mean and variance.\n",
    "\n",
    "###### 3. Finite variance: The individual variables in the sample must have a finite variance. This is necessary to ensure that the variance of the sample mean or sum does not become infinite as the sample size increases.\n",
    "\n",
    "###### 4. Large sample size: The sample size must be large enough for the distribution of the sample mean to be approximately normal. A common rule of thumb is that the sample size should be at least 30.\n",
    "\n",
    "#### If these assumptions are met, the CLT ensures that the sample mean or sum will be approximately normally distributed, even if the individual variables are not normally distributed. This makes the CLT a powerful tool in statistics and data analysis, allowing us to make inferences about population parameters based on sample data, and to test hypotheses about the mean of a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d68ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
